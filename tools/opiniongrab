#!/usr/bin/env python

# Copyright (c) 2018  Floyd Terbo

import argparse
import datetime
import json
import logging
import os
import os.path
import sys
import time
import urllib

import BeautifulSoup as BS
import requests

logging.basicConfig(level=logging.INFO)

HEADERS = {"User-Agent" : "SCOTUS Opinion Grabber (https://github.com/fterbo/scotus-tools)"}
BASE = "https://www.supremecourt.gov/"


def GET (url):
  logging.debug("GET: %s" % (url))
  return requests.get(url, headers=HEADERS)


def parse_args ():
  parser = argparse.ArgumentParser()
  parser.add_argument("-t", "--term", dest="term", type=int)
  parser.add_argument("--root", dest="root", type=str, default=".")
  args = parser.parse_args()
  return args

def scanOpinions (path, opts):
  r = GET("%s/opinions/slipopinion/%d" % (BASE, opts.term))
  if r.status_code != 200:
    print r.status_code
    sys.exit(1)

  root = BS.BeautifulSoup(r.content)

  # Opinions are (at the moment, anyhow) organized in expandable panels, which are conveniently
  # identified by using the "panel-body" class.  We could be as greedy as ordergrab is and avoid the
  # complications here, but we can glean some more data out of the table that might be useful if we
  # try to parse more structure
  panels = root.findAll("div", {"class" : "panel-body"})
  for panel in panels:
    rows = panel.findAll("tr")
    for row in rows[1:]:
      odata = {}
      cells = row.findAll("td")
      odata["R"] = int(cells[0].text)

      opath = "%s/%d" % (path, odata["R"])
      if not os.path.exists(opath):
        os.makedirs(opath)

      odata["date"] = time.mktime(datetime.datetime.strptime(cells[1].text, "%m/%d/%y").timetuple())
      try:
        odata["docket"] = int(cells[2].text.split("-")[1])
      except IndexError:
        odata["docket"] = int(cells[2].text.split(",")[0])

      aelem = cells[3].find("a")
      fname = aelem["href"].split("/")[-1]
      lpath = "%s/%s" % (opath, fname)
      if not os.path.exists(lpath):
        logging.info("Grabbing R-%d" % (odata["R"]))
        r = GET("%s/%s" % (BASE, aelem["href"]))
        with open(lpath, "w+") as f:
          f.write(r.content)
        odata["blurb"] = aelem.get("title")

      if len(cells) == 7:
        revised = cells[len(cells)-3].find("a")
        if revised:
          r = GET("%s/%s" % (BASE, revised["href"]))
          with open("%s/%s" % (opath, revised["href"].split("/")[-1]), "w+") as f:
            f.write(r.content)

      odata["justice"] = cells[len(cells)-2].text
      odata["prelim-part"] = cells[len(cells)-1].text

      with open("%s/info.json" % (opath), "w+") as f:
        f.write(json.dumps(odata))


if __name__ == '__main__':
  opts = parse_args()
  path = "%s/OT-%d/opinions" % (opts.root, opts.term)
  try:
    os.makedirs(path)
  except OSError:
    pass

  scanOpinions (path, opts)
